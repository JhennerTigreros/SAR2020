{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/twloehfelm/SAR2020/blob/master/03%20-%20Image_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SkHz0FVN6F8u"
   },
   "source": [
    "<table width=\"100%\">\n",
    "    <tr>\n",
    "        <td valign=\"top\"><img src=\"https://cdn.ymaws.com/www.abdominalradiology.org/graphics/logo.jpg\"/></td>\n",
    "        <td valign=\"middle\" align=\"right\"><h1>SAR 2020<br/>AI Masters Class</h1></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"center\" colspan=2><h1>Image Classifier</h1></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fE8-a8NmyNGR"
   },
   "source": [
    "**CHEST XRAY CLASSIFIER**\n",
    "\n",
    "Let's build an image classifier from scratch and see if we can use it to differentiate frontal from lateral chest x-rays.\n",
    "\n",
    "Frontal and lateral chest x-rays are so similar within-class and so different between classes that differentiating them is a trivial task for a neural network. But, you can use the *exact same code* to train the classifier to differentiate any other classes of images:\n",
    "\n",
    "*   Pneumothorax vs pneumonia vs normal\n",
    "*   Stroke vs no stroke\n",
    "*   HCC vs adenoma\n",
    "*   Hot dog vs not a hot dog\n",
    "\n",
    "The more subtle the differences between your classes, the more training data (and time) you'll need.\n",
    "\n",
    "---\n",
    "\n",
    "This tutorial is based on Lesson 1 of Practical Deep Learning for Coders v3, a free course offering from [fast.ai](https://course.fast.ai/). I strongly encourage anyone interested to head over to fast.ai to learn more - it's the best resource out there for learning and getting up to speed on image classification as well as more advanced tasks like object detection, image segmentation, and natural language processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCxnQYu5EF7l"
   },
   "outputs": [],
   "source": [
    "# Import the required fastai modules\n",
    "!pip3 install fastai | grep -v 'already satisfied'\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from fastai.callbacks.hooks import *\n",
    "from fastai.imports import *\n",
    "from fastai import *\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CygcMgenCkXv"
   },
   "outputs": [],
   "source": [
    "# clean out any old data just to be sure, such as if re-running cells\n",
    "!rm -rf images\n",
    "!rm -rf sample_data # Google supplies this but not needed\n",
    "\n",
    "# Download the CXRs for training\n",
    "!wget -q --no-check-certificate 'https://www.dropbox.com/s/p32oela6ac63d7e/cxr.zip' -O ./cxr.zip\n",
    "!mkdir images\n",
    "!cd images; unzip -q \"../cxr.zip\" \n",
    "!rm -rf ./images/__MACOSX\n",
    "!ls images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vK8BKS3wtkiP"
   },
   "outputs": [],
   "source": [
    "# Save the path to our image directory to a variable named path\n",
    "path = Path('/content/images/cxr/')\n",
    "# get_image_files is a convenience function from fastai.vision that looks in `path` and returns a list of all image files it finds\n",
    "filenames = get_image_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nbpsGOQZsICK"
   },
   "outputs": [],
   "source": [
    "print(filenames[99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K_GwBZsHz_JF"
   },
   "source": [
    "As you can tell from the example filename, the *image class* is encoded in the file name itself. This is a common method of labeling images for machine learning - it ensures that the correct label is always associated with each image rather than in a separate file.\n",
    "\n",
    "The images are all named in a consistent way:\n",
    "> `{class}_{serial number}.jpg`\n",
    "\n",
    "> `frontal_0001.jpg`, `lateral_0056.jpg`, etc.\n",
    "\n",
    "---\n",
    "**Protip**\n",
    "\n",
    "When you can identify a *pattern* that isolates the text you want from a longer string, you can use *regular expressions*, or *RegEx*, to extract the text. The RegEx pattern to extract the class (frontal or lateral) from the full file path ('/content/images/cxr/lateral_0062.jpg') is:\n",
    "\n",
    "\n",
    "> **`/([^/]+)_\\d+.jpg$`**\n",
    "\n",
    "\n",
    "We'll save this RegEx pattern as a variable called `pattern`.\n",
    "\n",
    "Learn more about RegEx and pratice at [Pythex.org](https://pythex.org/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ui-f4z6-0RRY"
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(r'/([^/]+)_\\d+.jpg$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_-_FuC20UL8"
   },
   "outputs": [],
   "source": [
    "# Set required arguments for the fastai ImageDataBunch\n",
    "validation_percentage=0.5 #We'll do a 50:50 split: train on 50%, validate on 50%\n",
    "batchsize = 8 # Network weights updated after each batch. Size depends on memory of GPU and image size\n",
    "imagesize=224 # Images will be resized to 224x224 px\n",
    "# Apply random image transformations: horizontal flip, small rotations, etc.\n",
    "# Essentially multiplies the number of unique images available\n",
    "transforms = get_transforms()\n",
    "np.random.seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ERzQpFjvDN9M"
   },
   "outputs": [],
   "source": [
    "# An ImageDataBunch is a fastai data construct that assembles the images and required settings\n",
    "# and prepares them for loading in to the neural network.\n",
    "# Different machine learning libraries have slightly different semantics for these data loading objects\n",
    "data = ImageDataBunch.from_name_re(\n",
    "    path, \n",
    "    filenames, \n",
    "    pattern, \n",
    "    valid_pct=validation_percentage, \n",
    "    ds_tfms = transforms, \n",
    "    size=imagesize, \n",
    "    bs=batchsize).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ajs0QFo80h3E"
   },
   "outputs": [],
   "source": [
    "# We can look at the ImageDataBunch and see that it contains separate training and validation datasets\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgyjvAAN0nxQ"
   },
   "outputs": [],
   "source": [
    "# The ImageDataBunch has two classes [frontal, lateral], adn 50 images each in the training and validation datasets\n",
    "data.classes, data.c, len(data.train_ds), len(data.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e10lFyR30rO5"
   },
   "outputs": [],
   "source": [
    "# We can display one batch of 8 images with their associates ground-truth labels\n",
    "# Note that some of the images have been arbitrarily flipped horizontally\n",
    "data.show_batch(rows=3, figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "459DWI6I1f8r"
   },
   "outputs": [],
   "source": [
    "# Build the neural network learner by passing it our ImageDataBunch\n",
    "# Note that we are basing it on an existing network, called Resnet34\n",
    "# Resnet34 is pretrained on ImageNet, which learned from millions of regular images\n",
    "# We are hoping to transfer what ImageNet already knows to the CXR domain\n",
    "learn = cnn_learner(\n",
    "    data,\n",
    "    models.resnet34,\n",
    "    metrics=(error_rate, accuracy)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4RnVd_T1WwU"
   },
   "outputs": [],
   "source": [
    "# Finally we'll start training the network!\n",
    "# We will have it go through all 50 training images 4 times\n",
    "# Each time through the entire training set is referred to as an epoch\n",
    "# Remember that we defined a batch as 8 images, so after every 8 images the network will adjust its settings\n",
    "# After each epoch it will report back it's current error rate and accuracy\n",
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KwoDrYxg2oFP"
   },
   "outputs": [],
   "source": [
    "# We can save the trained model and use it later to evaluate new CXRs\n",
    "learn.save('cxr-frontlat-stage1')\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XfgX0dew1xqI"
   },
   "outputs": [],
   "source": [
    "# The goal of training a neural network is to \"minimize the loss function\"\n",
    "# The Loss Function is a formula that quantifies how far from perfect performance on its assigned task the network is.\n",
    "# After each batch, the network measures how far off from perfect it is and adjusts its parameters \n",
    "# in such a way that it gets a little closer to perfect.\n",
    "# The amount by which parameters are adjusted is determined by the Learning Rate (LR)\n",
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOwYxEs91_ii"
   },
   "outputs": [],
   "source": [
    "# We can visualize the cases that the network got wrong or was right but less confident in\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_top_losses(9, figsize=(15,11), heatmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQc8zKfF2G2a"
   },
   "outputs": [],
   "source": [
    "# A confusion matrix plots predicted vs actual\n",
    "# It is most useful when there are several classes and you can see which classes it is confusing for which others\n",
    "interp.plot_confusion_matrix(figsize=(3,3), dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T-nvewd54LIG"
   },
   "outputs": [],
   "source": [
    "# Download a brand-new batch of chest x-rays unrelated to those used for training\n",
    "!wget --no-check-certificate 'https://www.dropbox.com/s/639j1pbq12gs107/palat.zip' -O ./palat.zip\n",
    "\n",
    "!cd images; unzip -q \"../palat.zip\" \n",
    "!rm -rf ./images/__MACOSX\n",
    "!ls images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pu5yvrSe2uey"
   },
   "outputs": [],
   "source": [
    "# Load the learner (the fully trained network) and apply it to the new images\n",
    "learn = load_learner('/content/images/cxr/', test=ImageImageList.from_folder('/content/images/palat/test/'))\n",
    "pred,y = learn.get_preds(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9EpDjKnn4gij"
   },
   "outputs": [],
   "source": [
    "# Look at a snapshot of predictions - we can see that it is a list where each entry is two numbers -\n",
    "# the liklihood the network assigns to the given CXR being a PA or lateral.\n",
    "# The higher number is considered to be the class assignment for that CXR\n",
    "pred[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2iXZg-eu4met"
   },
   "outputs": [],
   "source": [
    "ims = learn.data.test_ds.x\n",
    "classes = ['frontal','lateral']\n",
    "# Argmax simply chooses the index of the highest number of the available options\n",
    "# In this case it choose the higher number for each row in the predictions list\n",
    "lbls = np.argmax(pred, axis=1)\n",
    "lbls[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2iXZg-eu4met"
   },
   "outputs": [],
   "source": [
    "rows = 40\n",
    "cols = 10\n",
    "figsize=(20,70)\n",
    "fig,axes = plt.subplots(rows,cols,figsize=figsize)\n",
    "fig.suptitle('predictions', weight='bold',size=14)\n",
    "for idx,im in enumerate(ims):\n",
    "  im.show(ax=axes.flat[idx], title=classes[lbls[idx]])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMTc1Wq1KGW1SPSzLyX2lPj",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "SAR 2020 - Image Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
